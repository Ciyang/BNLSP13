Human language communication is efficient, in that people need not always say every detail in order to be understood. Rather, speakers only say what is most relevant, and listeners can seemingly effortlessly grasp the intended meaning beyond what is literally said. This ability to do pragmatic inference has been long studied and the \emph{conversational implicature} theory by Grice \cite{Grice} is one of the most prominent theories in the field. However, since it is hard to formalize the \emph{Cooperative Principle} and the \emph{Conversational Maxims}, Grice's theory is not precise enough to give empirically testable predictions, especially quantitative predictions.

The Bayesian \emph{Rational Speech Act} (RSA) model attempts to address this issue by using information-theoretic notions together with the Bayesian inference framework. It has been shown that the model could yield quantitative predictions that are highly correlated to actual human judgments \cite{Frank}.

Despite the RSA model's theoretical advantage in that it provides us with quantitative predictions and its empirical success, if we analyze the design of the model, we will find several choices that are not \emph{prima facie} obvious and thus need further clarification. These choices have their alternatives in the closely related game-theoretic approaches to pragmatics (e.g. \cite{Benz2007,Jager2013}), which have similar but slightly different conceptual motivations. Hence it is important to systematically compare the original RSA model with all these alternatives and test their predictions on empirical data, to gain a better understanding of the nature of human pragmatic inference.

The outline of the paper is as follows. We first introduce the simple referential communication game investigated in \cite{Frank} and the original RSA model proposed there. Next we analyze a few design choices in this model and introduce their alternatives in game-theoretic pragmatics. Finally we report on the result of an experiment similar to the original one, and compare the predictions of different models to the new data.