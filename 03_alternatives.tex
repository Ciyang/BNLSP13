The RSA model has a theoretical advantage over traditional formal
pragmatic theories in that it provides quantitative predictions, and
it has been shown to fit relevant empirical data well. However, if we
want to learn more about pragmatic reasoning about referential
expressions, it will be worthwhile to examine RSA carefully to pin
down its major components, to spell out its main design choices and
their underlying assumptions, and to test their contribution to the
predictive power of the model through statistical comparison with
natural alternatives. In this section, we will therefore compare the
RSA model to closely related game theoretic approaches, that likewise
assume that speakers and listeners form cascading beliefs about mutual behavior
and seek to optimize their behavior based on these beliefs
\cite{Rabin1990:Communication-b,Stalnaker:SayingMeaningCredibility,BenzvanRooijOptimalAssertions2007,Franke2011:Quantity-Implic,Jager2013:Rationalizable-}.\footnote{See
\cite{FrankeJager2013:Pragmatic-Back-} for overview and comparison
of game theoretic and Bayesian models.} Doing so
let's us describe a class of potential alternatives to RSA. We will
then compare the predictive power of these given relevant empirical
data in later sections.

There are three closely related notions, i.e., \emph{belief},
\emph{goal} and \emph{action}, that play a crucial role in RSA as well
as game theoretic models. The relation and distinction between them
can be best illustrated by looking at (\ref{Bayesian_speaker}),
repeated here:
$$\sigma(m \mid t) \propto \exp(\lambda_\mathrm{S} \cdot (\log \mathcal{U}(t\mid \intp{m})-\mbox{Cost}(m))) \enspace .$$
The term $\mathcal{U}(t\mid \intp{m})$ is the speaker's \emph{belief}
about the listener's interpretation of the utterance. The expected
utility $\mbox{U}(m,t)=\log \mathcal{U}(t\mid
\intp{m})-\mbox{Cost}(m)$ describes the speaker's \emph{goal} of
communication, i.e., inducing a belief that is as close as possible to
her own with minimal effort. The production rule $\sigma(m \mid t)$ on
the left-hand side specifies the speaker's \emph{action}, as it
defines the probability with which, according to RSA, speakers would
choose a particular expression. The soft-max rule connects these
notions, as a (sub-)rational agent's action depends on his belief and
goal. While the RSA and game theoretic models all share this general
architecture in their designs, they vary in the specific
interpretations of the three ingredients, which reflect different
views and emphasis on language and communication and give rise to a
series of interesting and important empirical questions. Again, let us
continue with the speaker model (\ref{Bayesian_speaker}) to illustrate
some points of divergence and formally define the corresponding
alternatives.

First of all, although it is prima facie reasonable to hypothesize, as
\cite{Frank} do, that the empirically measured perceptual salience
$\mathcal{S}(\cdot)$ is common knowledge between speaker and listener,
it does not actually affect RSA's production rule
(\ref{Bayesian_speaker}) at all. This makes it unclear in what sense
the speaker can be said to know the listener's perceptual salience,
since neither his beliefs nor actions depend on it. A natural variant,
which is used in some game theoretic models, would replace the literal
listener's uniform distribution $\mathcal{U}(t)$ in
(\ref{Bayesian_literal}) with the salience prior
$\mathcal{S}(t)$. This leads to the alternative production rule:
\begin{equation} \label{Bayesian_speaker_salience}
\sigma_\mathcal{S}(m \mid t) \propto \exp(\lambda_\mathrm{S} \cdot (\log \mathcal{S}(t\mid \intp{m})-\mbox{Cost}(m))) \enspace .
\end{equation}


Secondly, RSA measures the informativeness of an utterance $m$, which
is a crucial part of the communicative goal, in terms of how close the
induced belief of the literal listener is from the speaker's own
belief. This means that the RSA model sees the goal of communication
as conveying belief. While it is normally true that language does
convey the belief of the speaker, it is questionable at least in this
referential scenario whether letting the listener form a proper belief
is the ultimate goal of the communication. After all, if the speaker
wants to refer to something, it seems that in the end what matters is
whether the listener actually picks out the intended referent
successfully (e.g., when the speaker wants the listener to pass
something). This view is inherent in game theoretic approaches where
agents' beliefs are backed up by explicit formulations of their
utilities. We might call this latter view \emph{action-oriented}, in
contrast to the \emph{belief-oriented} view of communication which the
RSA model adopts, as it interprets the goal of communication as
invoking the intended action rather than forming an accurate
belief.\footnote{Note that the two views are clearly intimately
  related, despite our emphasis on their differences here. An accurate
  belief is usually helpful for choosing a desired action. In fact,
  forming a belief can itself be seen as an action that the listener
  performs, which might well be all that the speaker cares about in
  many everyday situations, e.g., casual talks or responses to
  inquiries of information. Also, the relevant actions might vary
  greatly across situations which makes belief formation a practical
  alternative to serve as the goal. Nevertheless, they are still
  essentially different views in spite of the fact that they often
  coincide in practice. The referential communication scenario we
  investigate in this paper reflects the distinction.} Thus, according
to this view, the informativeness of a message would be measured as
the probability of the listener choosing the intended
referent. Formally speaking, we have the action-oriented speaker model
  
\begin{equation} \label{Bayesian_speaker_action}
\sigma_\mathrm{a}(m \mid t) \propto \exp(\lambda_\mathrm{S} \cdot (\rho_0(t\mid m)-\mbox{Cost}(m))) \enspace .
\end{equation}

Hence we have four types of speaker models that differ in either the speaker's belief about the literal listener, or the speaker's goal of communication. We now introduce a uniform notation $\sigma_{xy},\ x\in\{a,b\},y\in\{\mathcal{U},\mathcal{S}\}$ for them:
\begin{equation} \label{Bayesian_speaker_uniform_action}
\sigma_{\mathrm{a}y}(m \mid t) \propto \exp(\lambda_\mathrm{S} \cdot ( y(t\mid m)-\mbox{Cost}(m))),
\end{equation}
\begin{equation} \label{Bayesian_speaker_uniform_belief}
\sigma_{\mathrm{b}y}(m \mid t) \propto \exp(\lambda_\mathrm{S} \cdot (\log y(t\mid m)-\mbox{Cost}(m))),
\end{equation}
where $\mathcal{U}$ is the uniform prior and $\mathcal{S}$ is the
salience prior. For example, in the original RSA model, the speaker
does not take listener's salience prior into account and he has a
belief-oriented goal of communication. Thus it will be denoted as
$\sigma_{\mathrm{b}\mathcal{U}}$.

Finally, the original RSA speaker model of \cite{Frank} has
$\mbox{Cost}(m)=0$ for all $m$, which means that the potential speaker
preference in different utterances is not taken into account (but not
so in, e.g., \cite{Bergen2012}). As we previously pointed out, our
intuition seems to suggest a preference for nouns over adjectives as
referential expressions.\footnote{The rich tradition on referential
  expression generation \cite{KramerDeemter2012:Computational-G} has
  also identified the need to take speaker preferences into account,
  and \cite{GattGompel2013:Are-we-Bayesian} criticize RSA on these
  grounds as well.} Since it is an empirical question whether, to what
direction or to what extent such a preference exists, we leave open
all the possibilities. Technically speaking, since only the difference
in costs matters, we define the cost function using a constant $c\in
\mathbb{R}$
\begin{equation} \label{cost}
\mbox{Cost}(m)=c \mbox{ if } m \mbox{ is an adjective and }0 \mbox{ otherwise} \enspace . 
\end{equation}
If $c>0$ it means there is a preference for nouns and if $c<0$ then the preference is for adjectives. No preference exists if $c=0$.

Now we turn to the listener model (\ref{Bayesian_rec_update}), where the boundary between belief, goal and action becomes less clear:
$$\rho(t \mid m) \propto \mathcal{S}(t)\cdot \sigma(m \mid t) \enspace . $$

Let us start from the relatively clear part. As pointed out
previously, the likelihood term $\sigma(m \mid t)$ is the listener's
belief about how the speaker behaves. One natural question is to what
extent the listener's belief correlates with the actual production. We
thus treat the speaker's production term $\sigma(m \mid t)$ in the
listener's model as a parameter, making the association with a belief
about production of the listener model explicit:
\begin{equation} \label{listener-production}
\rho(\sigma_{xy})(t \mid m) \propto \mathcal{S}(t)\cdot \sigma_{xy}(m \mid t) \enspace .
\end{equation}
Note that the speaker's production rule has two parameters
$\lambda_\mathrm{S},c$ which are also included in the above
specification of the listener model.

Next, even though our intuition suggests different objects have different perceptual salience and thus might affect our judgment, it is after all an empirical question whether it is relevant in the interpretation of referential expressions. It is in principle possible that the listener does not take into account the perceptual salience in his reasoning, which means he has a uniform prior over the referents:
\begin{equation} \label{listener-production-uniform}
\rho_{\mathcal{U}}(\sigma_{xy})(t \mid m) \propto \mathcal{U}(t)\cdot \sigma_{xy}(m \mid t) \enspace .
\end{equation}

Finally, since the RSA model adopts a belief-oriented view on the goal
of communication, its listener model only consists of the belief about
the intended referent after hearing the utterance, obtained by a Bayes
update. However, according to the action-oriented view, this is not
quite the end of the story. The listener often needs to decide the
exact referent of a referential expression. (Again, consider the case
in which the listener is asked to pass something.) Hence in such cases
the listener will choose an object by, essentially, (soft-)maximizing
over his beliefs. Formally, the action-oriented listener model
becomes:
\begin{equation} \label{listener-action}
\rho_{\mathrm{a}v}(\sigma_{xy})(t \mid m) \propto \exp(\lambda_\mathrm{L} \cdot \rho_{\mathrm{b}v}(\sigma_{xy})(t \mid m) ),
\end{equation}
where $v\in\{\mathcal{U},\mathcal{S}\}$, $\lambda_\mathrm{L}$ is the
parameter measuring the listener's degree of rationality, and
$\rho_{\mathrm{b}v}$ is the belief-oriented model that does the
Bayesian update:
\begin{equation} \label{listener-belief}
\rho_{\mathrm{b}v}(\sigma_{xy})(t \mid m) \propto v(t)\cdot \sigma_{xy}(m \mid t) \enspace .
\end{equation}
For instance, the original RSA listener model is a belief-oriented one with the perceptual salience as prior, whose belief about the speaker is $\sigma_{\mathrm{b}\mathcal{U}}$, hence it is denoted as $\rho_{\mathrm{b}\mathcal{S}}(\sigma_{\mathrm{b}\mathcal{U}})$.


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "main"
%%% TeX-PDF-mode: t
%%% End: